# Trustworthy-AI

**Dataset Ownership Verification**
| Paper Title                                      | Code Available | Conference / Journal | Tag (Read) |
|--------------------------------------------------|----------------|----------------------|------------|
| Black-Box Dataset Ownership Verification via Backdoor Watermarking  | Yes            | TIFS 2023           | Yes          |
| ZeroMark: Towards Dataset Ownership Verification without Disclosing Watermarks | Yes             | NIPS 2024        | No          |
| Domain watermark: Effective and harmless dataset copyright protection is closed at hand | Yes | NIPS 2023 | No |
| Untargeted Backdoor Watermark: Towards Harmless and Stealthy Dataset Copyright Protection | Yes | NIPS 2022 | No |
| Pointncbw: Towards dataset ownership verification for point clouds via negative clean-label backdoor watermark | Yes | TIFS 2024 | No |

**Adversarial Attacks&Training**
Note:
- Keep track on this guy: Francesco Croce. He researched on Adversarial Robustness during his PHD strage. Now he focus on Jailbreaking, Backdoor and so on.


| Paper Title                                      | Code Available | Conference / Journal | Tag (Read) |
|--------------------------------------------------|----------------|----------------------|------------|
| Towards Deep Learning Models Resistant to Adversarial Attacks  | Yes            | ICLR 2018           | Yes          |
| Explaining and Harnessing Adversarial Examples | Yes | ICLR 2015 | Yes |
| Better Diffusion Models Further Improve Adversarial Training | Yes | ICML 2023 | No |
| Defensive Unlearning with Adversarial Training for Robust Concept Erasure in Diffusion Models | Yes | NIPS 2024 | No |
| Global Filter Networks for Image Classification | Yes | NIPS 2021 | No |
| Improving Robustness using Generated Data | No | NIPS 2021 | No |
| Data Augmentation Can Improve Robustness | No | NIPS 2021 | No |
| Frequency Domain Model Augmentation for Adversarial Attack | Yes | ECCV 2022 | Yes |
| LAS-AT: Adversarial Training With Learnable Attack Strategy | Yes | CVPR 2022 | Yes |
| Decoupled Kullback-Leibler Divergence Loss | Yes | NIPS 2024 | No |
| Towards Efficient Training and Evaluation of Robust Models against $l_0$ Bounded Adversarial Perturbations | Yes | ICML 2024 | No |
| **RobustBench: a standardized adversarial robustness benchmark** | Yes | NIPS 2021 | No |
| Minimally distorted Adversarial Examples with a Fast Adaptive Boundary Attack | Yes | ICML 2020 | No |
| Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks | Yes | ICML 2020 | Yes |
| Overfitting in adversarially robust deep learning | Yes | ICML 2020 | No |
| Black-Box Sparse Adversarial Attack via Multi-Objective Optimisa | Yes | CVPR 2023 | No|
| Sparse and Imperceivable Adversarial Attack | Yes | ICCV 2019 | No |
| Strong Transferable Adversarial Attacks via Ensembled Asymptotically Normal Distribution Learning | Yes | CVPR 2024 | Yes |
| The Best Defense Is a Good Offense: Adversarial Augmentation Against Adversarial Attacks  | Yes | CVPR 2023 | No |
| Simple Black-box Adversarial Attacks | Yes | ICML 2019 | No |
| Boosting Adversarial Attacks With Momentum | Yes | CVPR 2018 | Yes |
| Adversarial Training for Free! | Yes | NIPS 2019 | Yes |
| Using Pre-Training Can Improve Model Robustness and Uncertainty | Yes | ICML 2019 | No |
| Phantom Sponges: Exploiting Non-Maximum Suppression to Attack Deep Object Detectors | Yes | WACV 2023 | No |









